{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu</th>\n",
       "      <th>diskio</th>\n",
       "      <th>diskioRead</th>\n",
       "      <th>diskioWritten</th>\n",
       "      <th>mem</th>\n",
       "      <th>networkReceived</th>\n",
       "      <th>networkTransmitted</th>\n",
       "      <th>replica</th>\n",
       "      <th>requests</th>\n",
       "      <th>responsetime</th>\n",
       "      <th>totalcpu</th>\n",
       "      <th>totalcpuUtilization</th>\n",
       "      <th>totalmemory</th>\n",
       "      <th>totalmemoryUtilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.452470</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.484572e+04</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>7.686411e+02</td>\n",
       "      <td>690.618472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.427801</td>\n",
       "      <td>12.0</td>\n",
       "      <td>76.330988</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.168922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.314931</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>903.680000</td>\n",
       "      <td>7.635895e+06</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>4.423151e+06</td>\n",
       "      <td>44196.825694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.441701</td>\n",
       "      <td>12.0</td>\n",
       "      <td>76.330988</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.168922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.499113</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>1001.244444</td>\n",
       "      <td>9.543407e+06</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>4.011359e+06</td>\n",
       "      <td>41064.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.429230</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.329697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.085528</td>\n",
       "      <td>0.073156</td>\n",
       "      <td>1001.244444</td>\n",
       "      <td>9.533212e+06</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>4.012145e+06</td>\n",
       "      <td>42053.311111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.421655</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.329697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.452724</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>182.044444</td>\n",
       "      <td>2.628813e+06</td>\n",
       "      <td>0.119376</td>\n",
       "      <td>3.909378e+03</td>\n",
       "      <td>3469.288889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.439443</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.213889</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.159327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cpu    diskio   diskioRead  diskioWritten       mem  networkReceived  \\\n",
       "0  7.452470  0.000129     0.000000   1.484572e+04  0.006211     7.686411e+02   \n",
       "1  6.314931  0.056578   903.680000   7.635895e+06  0.006211     4.423151e+06   \n",
       "2  9.499113  0.073244  1001.244444   9.543407e+06  0.006211     4.011359e+06   \n",
       "3  6.085528  0.073156  1001.244444   9.533212e+06  0.026095     4.012145e+06   \n",
       "4  9.452724  0.021956   182.044444   2.628813e+06  0.119376     3.909378e+03   \n",
       "\n",
       "   networkTransmitted  replica  requests  responsetime  totalcpu  \\\n",
       "0          690.618472      1.0       7.0      0.427801      12.0   \n",
       "1        44196.825694      1.0      42.0      0.441701      12.0   \n",
       "2        41064.000000      1.0      76.0      0.429230      12.0   \n",
       "3        42053.311111      1.0     112.0      0.421655      12.0   \n",
       "4         3469.288889      1.0     140.0      0.439443      12.0   \n",
       "\n",
       "   totalcpuUtilization   totalmemory  totalmemoryUtilization  \n",
       "0            76.330988  5.045532e+10               10.168922  \n",
       "1            76.330988  5.045532e+10               10.168922  \n",
       "2            13.216667  5.045532e+10               10.329697  \n",
       "3            13.216667  5.045532e+10               10.329697  \n",
       "4            14.213889  5.045532e+10               10.159327  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "output_dir = os.path.join(cwd, \"../data\")\n",
    "df = pd.read_csv(os.path.join(output_dir, \"combined_sentimentanalysis.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(output_dir, \"combined_sentimentanalysistest.csv\"))\n",
    "df_test = df_test.drop(df_test[df_test.responsetime > 2].index)\n",
    "df.pop('Time')\n",
    "df_test.pop('Time')\n",
    "#df_test = pd.read_csv(os.path.join(output_dir, \"figlet1599056546.006096_1599063766.431225.csv\"))\n",
    "df = df.drop(df[df.responsetime > 3].index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu</th>\n",
       "      <th>diskio</th>\n",
       "      <th>diskioRead</th>\n",
       "      <th>diskioWritten</th>\n",
       "      <th>mem</th>\n",
       "      <th>networkReceived</th>\n",
       "      <th>networkTransmitted</th>\n",
       "      <th>replica</th>\n",
       "      <th>requests</th>\n",
       "      <th>responsetime</th>\n",
       "      <th>totalcpu</th>\n",
       "      <th>totalcpuUtilization</th>\n",
       "      <th>totalmemory</th>\n",
       "      <th>totalmemoryUtilization</th>\n",
       "      <th>total_cpu_util</th>\n",
       "      <th>total_mem_util</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.452470</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.484572e+04</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>7.686411e+02</td>\n",
       "      <td>690.618472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.427801</td>\n",
       "      <td>12.0</td>\n",
       "      <td>76.330988</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.168922</td>\n",
       "      <td>9.159719</td>\n",
       "      <td>513.076211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.314931</td>\n",
       "      <td>0.056578</td>\n",
       "      <td>903.680000</td>\n",
       "      <td>7.635895e+06</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>4.423151e+06</td>\n",
       "      <td>44196.825694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.441701</td>\n",
       "      <td>12.0</td>\n",
       "      <td>76.330988</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.168922</td>\n",
       "      <td>9.159719</td>\n",
       "      <td>513.076211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.499113</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>1001.244444</td>\n",
       "      <td>9.543407e+06</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>4.011359e+06</td>\n",
       "      <td>41064.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.429230</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.329697</td>\n",
       "      <td>1.586000</td>\n",
       "      <td>521.188136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.085528</td>\n",
       "      <td>0.073156</td>\n",
       "      <td>1001.244444</td>\n",
       "      <td>9.533212e+06</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>4.012145e+06</td>\n",
       "      <td>42053.311111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.421655</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.329697</td>\n",
       "      <td>1.586000</td>\n",
       "      <td>521.188136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.452724</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>182.044444</td>\n",
       "      <td>2.628813e+06</td>\n",
       "      <td>0.119376</td>\n",
       "      <td>3.909378e+03</td>\n",
       "      <td>3469.288889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.439443</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.213889</td>\n",
       "      <td>5.045532e+10</td>\n",
       "      <td>10.159327</td>\n",
       "      <td>1.705667</td>\n",
       "      <td>512.592066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cpu    diskio   diskioRead  diskioWritten       mem  networkReceived  \\\n",
       "0  7.452470  0.000129     0.000000   1.484572e+04  0.006211     7.686411e+02   \n",
       "1  6.314931  0.056578   903.680000   7.635895e+06  0.006211     4.423151e+06   \n",
       "2  9.499113  0.073244  1001.244444   9.543407e+06  0.006211     4.011359e+06   \n",
       "3  6.085528  0.073156  1001.244444   9.533212e+06  0.026095     4.012145e+06   \n",
       "4  9.452724  0.021956   182.044444   2.628813e+06  0.119376     3.909378e+03   \n",
       "\n",
       "   networkTransmitted  replica  requests  responsetime  totalcpu  \\\n",
       "0          690.618472      1.0       7.0      0.427801      12.0   \n",
       "1        44196.825694      1.0      42.0      0.441701      12.0   \n",
       "2        41064.000000      1.0      76.0      0.429230      12.0   \n",
       "3        42053.311111      1.0     112.0      0.421655      12.0   \n",
       "4         3469.288889      1.0     140.0      0.439443      12.0   \n",
       "\n",
       "   totalcpuUtilization   totalmemory  totalmemoryUtilization  total_cpu_util  \\\n",
       "0            76.330988  5.045532e+10               10.168922        9.159719   \n",
       "1            76.330988  5.045532e+10               10.168922        9.159719   \n",
       "2            13.216667  5.045532e+10               10.329697        1.586000   \n",
       "3            13.216667  5.045532e+10               10.329697        1.586000   \n",
       "4            14.213889  5.045532e+10               10.159327        1.705667   \n",
       "\n",
       "   total_mem_util  \n",
       "0      513.076211  \n",
       "1      513.076211  \n",
       "2      521.188136  \n",
       "3      521.188136  \n",
       "4      512.592066  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df\n",
    "df_t['total_cpu_util'] = (df['totalcpuUtilization']*df['totalcpu'])/100\n",
    "df_t['total_mem_util'] = (df['totalmemoryUtilization']*df['totalmemory'])*1e-9\n",
    "df_t['responsetime'] = df['responsetime']\n",
    "df_t['requests'] = df['requests']\n",
    "df_t['replica'] = df['replica']\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.drop(df_t[df_t.totalcpu > 16].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu</th>\n",
       "      <th>diskio</th>\n",
       "      <th>diskioRead</th>\n",
       "      <th>diskioWritten</th>\n",
       "      <th>mem</th>\n",
       "      <th>networkReceived</th>\n",
       "      <th>networkTransmitted</th>\n",
       "      <th>replica</th>\n",
       "      <th>requests</th>\n",
       "      <th>responsetime</th>\n",
       "      <th>totalcpu</th>\n",
       "      <th>totalcpuUtilization</th>\n",
       "      <th>totalmemory</th>\n",
       "      <th>totalmemoryUtilization</th>\n",
       "      <th>total_cpu_util</th>\n",
       "      <th>total_mem_util</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.558822</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.458176e+05</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>3.544833e+04</td>\n",
       "      <td>42588.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.421643</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.020732</td>\n",
       "      <td>1.011896e+11</td>\n",
       "      <td>5.857406</td>\n",
       "      <td>6.244976</td>\n",
       "      <td>592.708608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.638769</td>\n",
       "      <td>0.071467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.464036e+06</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>3.973986e+06</td>\n",
       "      <td>78708.644444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.421552</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.889822</td>\n",
       "      <td>1.011896e+11</td>\n",
       "      <td>5.875336</td>\n",
       "      <td>5.253557</td>\n",
       "      <td>594.522931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.617630</td>\n",
       "      <td>0.071378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.441007e+06</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>3.987661e+06</td>\n",
       "      <td>77995.288889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.426619</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.889822</td>\n",
       "      <td>1.011896e+11</td>\n",
       "      <td>5.875336</td>\n",
       "      <td>5.253557</td>\n",
       "      <td>594.522931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.166747</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.423440e+06</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>3.976253e+06</td>\n",
       "      <td>81823.577778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.412297</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>1.011896e+11</td>\n",
       "      <td>5.921870</td>\n",
       "      <td>2.496000</td>\n",
       "      <td>599.231693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.616754</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.503111e+04</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>3.794593e+04</td>\n",
       "      <td>63292.422222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.417079</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>1.011896e+11</td>\n",
       "      <td>5.921870</td>\n",
       "      <td>2.496000</td>\n",
       "      <td>599.231693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cpu    diskio  diskioRead  diskioWritten       mem  networkReceived  \\\n",
       "0  2.558822  0.005156         0.0   1.458176e+05  0.003213     3.544833e+04   \n",
       "1  3.638769  0.071467         0.0   9.464036e+06  0.003213     3.973986e+06   \n",
       "2  4.617630  0.071378         0.0   9.441007e+06  0.058293     3.987661e+06   \n",
       "3  3.166747  0.069244         0.0   9.423440e+06  0.058293     3.976253e+06   \n",
       "4  4.616754  0.000089         0.0   2.503111e+04  0.058293     3.794593e+04   \n",
       "\n",
       "   networkTransmitted  replica  requests  responsetime  totalcpu  \\\n",
       "0        42588.666667      1.0       8.0      0.421643      24.0   \n",
       "1        78708.644444      1.0      43.0      0.421552      24.0   \n",
       "2        77995.288889      1.0      78.0      0.426619      24.0   \n",
       "3        81823.577778      1.0     114.0      0.412297      24.0   \n",
       "4        63292.422222      1.0     141.0      0.417079      24.0   \n",
       "\n",
       "   totalcpuUtilization   totalmemory  totalmemoryUtilization  total_cpu_util  \\\n",
       "0            26.020732  1.011896e+11                5.857406        6.244976   \n",
       "1            21.889822  1.011896e+11                5.875336        5.253557   \n",
       "2            21.889822  1.011896e+11                5.875336        5.253557   \n",
       "3            10.400000  1.011896e+11                5.921870        2.496000   \n",
       "4            10.400000  1.011896e+11                5.921870        2.496000   \n",
       "\n",
       "   total_mem_util  \n",
       "0      592.708608  \n",
       "1      594.522931  \n",
       "2      594.522931  \n",
       "3      599.231693  \n",
       "4      599.231693  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['total_cpu_util'] = (df_test['totalcpuUtilization']*df_test['totalcpu'])/100\n",
    "df_test['total_mem_util'] = (df_test['totalmemoryUtilization']*df_test['totalmemory'])*1e-9\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_t)\n",
    "train_df = df_t[0:int(n*0.8)]\n",
    "eval_df = df_t[int(n*0.8):]\n",
    "test_df = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df[[col for col in train_df.columns if col != 'requests']]\n",
    "y_train = train_df['requests']\n",
    "x_val = eval_df[[col for col in eval_df.columns if col != 'requests']]\n",
    "y_val = eval_df['requests']\n",
    "x_test = test_df[[col for col in test_df.columns if col != 'requests']]\n",
    "y_test = test_df['requests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_arr = scaler.fit_transform(df_train)\n",
    "val_arr = scaler.transform(df_val)\n",
    "test_arr = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stack three slices, the length of the total window:\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.example = example_inputs, example_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='requests', max_subplots=3):\n",
    "  inputs, labels = self.example\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plot_col_index = self.column_indices[plot_col]\n",
    "  max_n = min(max_subplots, len(inputs))\n",
    "  for n in range(max_n):\n",
    "    plt.subplot(3, 1, n+1)\n",
    "    plt.ylabel(f'{plot_col} [normed]')\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if self.label_columns:\n",
    "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "    else:\n",
    "      label_col_index = plot_col_index\n",
    "\n",
    "    if label_col_index is None:\n",
    "      continue\n",
    "\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "    if model is not None:\n",
    "      predictions = model(inputs)\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "\n",
    "    if n == 0:\n",
    "      plt.legend()\n",
    "\n",
    "  plt.xlabel('Time [h]')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element is an (inputs, label) pair\n",
    "w2.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in w2.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single step models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=['requests'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in single_step_window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=column_indices['requests'])\n",
    "\n",
    "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=60, label_width=60, shift=1,\n",
    "    label_columns=['requests'])\n",
    "\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', single_step_window.example[0].shape)\n",
    "print('Output shape:', baseline(single_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', single_step_window.example[0].shape)\n",
    "print('Output shape:', linear(single_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(linear, single_step_window)\n",
    "\n",
    "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
    "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', baseline(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=linear.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense, single_step_window)\n",
    "\n",
    "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
    "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=['requests'])\n",
    "\n",
    "conv_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_window.plot()\n",
    "plt.title(\"Given 3 values as input, predict 1 into the future.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', conv_window.example[0].shape)\n",
    "print('Output shape:', multi_step_dense(conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_step_dense, conv_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
    "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_window.plot(multi_step_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "try:\n",
    "  print('Output shape:', multi_step_dense(wide_window.example[0]).shape)\n",
    "except Exception as e:\n",
    "  print(f'\\n{type(e).__name__}:{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conv model on `conv_window`\")\n",
    "print('Input shape:', conv_window.example[0].shape)\n",
    "print('Output shape:', conv_model(conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(conv_model, conv_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
    "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wide window\")\n",
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Labels shape:', wide_window.example[1].shape)\n",
    "print('Output shape:', conv_model(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 60\n",
    "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
    "wide_conv_window = WindowGenerator(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    label_columns=['requests'])\n",
    "\n",
    "wide_conv_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wide conv window\")\n",
    "print('Input shape:', wide_conv_window.example[0].shape)\n",
    "print('Labels shape:', wide_conv_window.example[1].shape)\n",
    "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_conv_window.plot(conv_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', lstm_model(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(lstm_model, wide_window)\n",
    "\n",
    "#IPython.display.clear_output()\n",
    "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
    "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "plt.ylabel('mean_absolute_error [requests, normalized]')\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(),\n",
    "           rotation=45)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    # `WindowGenerator` returns all features as labels if you \n",
    "    # don't set the `label_columns` argument.\n",
    "    input_width=1, label_width=1, shift=1)\n",
    "\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=60, label_width=60, shift=1)\n",
    "\n",
    "for example_inputs, example_labels in wide_window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline()\n",
    "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n",
    "performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(dense, single_step_window)\n",
    "\n",
    "#IPython.display.clear_output()\n",
    "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
    "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=60, label_width=60, shift=1)\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=num_features)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(lstm_model, wide_window)\n",
    "\n",
    "#IPython.display.clear_output()\n",
    "val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n",
    "performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualWrapper(tf.keras.Model):\n",
    "  def __init__(self, model):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "\n",
    "  def call(self, inputs, *args, **kwargs):\n",
    "    delta = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "    # The prediction for each timestep is the input\n",
    "    # from the previous time step plus the delta\n",
    "    # calculated by the model.\n",
    "    return inputs + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "residual_lstm = ResidualWrapper(\n",
    "    tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(\n",
    "        num_features,\n",
    "        # The predicted deltas should start small\n",
    "        # So initialize the output layer with zeros\n",
    "        kernel_initializer=tf.initializers.zeros)\n",
    "]))\n",
    "\n",
    "history = compile_and_fit(residual_lstm, wide_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
    "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(),\n",
    "           rotation=45)\n",
    "plt.ylabel('MAE (average over all outputs)')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in performance.items():\n",
    "  print(f'{name:15s}: {value[1]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_STEPS = 60\n",
    "multi_window = WindowGenerator(input_width=60,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS)\n",
    "\n",
    "multi_window.plot()\n",
    "multi_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
    "\n",
    "last_baseline = MultiStepLastBaseline()\n",
    "last_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                      metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "multi_val_performance = {}\n",
    "multi_performance = {}\n",
    "\n",
    "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
    "multi_performance['Last'] = last_baseline.evaluate(multi_window.val, verbose=0)\n",
    "multi_window.plot(last_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return inputs\n",
    "\n",
    "repeat_baseline = RepeatBaseline()\n",
    "repeat_baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                        metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
    "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(repeat_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-shot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "    # Shape => [batch, 1, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_linear_model, multi_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
    "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(multi_linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dense_model = tf.keras.Sequential([\n",
    "    # Take the last time step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "    # Shape => [batch, 1, dense_units]\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Shape => [batch, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_dense_model, multi_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
    "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(multi_dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_conv_model, multi_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
    "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(multi_conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units]\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
    "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.train, verbose=0)\n",
    "multi_window.plot(multi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced: Autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "  def __init__(self, units, out_steps):\n",
    "    super().__init__()\n",
    "    self.out_steps = out_steps\n",
    "    self.units = units\n",
    "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(self, inputs):\n",
    "  # inputs.shape => (batch, time, features)\n",
    "  # x.shape => (batch, lstm_units)\n",
    "  x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "  # predictions.shape => (batch, features)\n",
    "  prediction = self.dense(x)\n",
    "  return prediction, state\n",
    "\n",
    "FeedBack.warmup = warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs, training=None):\n",
    "  # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "  predictions = []\n",
    "  # Initialize the lstm state\n",
    "  prediction, state = self.warmup(inputs)\n",
    "\n",
    "  # Insert the first prediction\n",
    "  predictions.append(prediction)\n",
    "\n",
    "  # Run the rest of the prediction steps\n",
    "  for n in range(1, self.out_steps):\n",
    "    # Use the last prediction as input.\n",
    "    x = prediction\n",
    "    # Execute one lstm step.\n",
    "    x, state = self.lstm_cell(x, states=state,\n",
    "                              training=training)\n",
    "    # Convert the lstm output to a prediction.\n",
    "    prediction = self.dense(x)\n",
    "    # Add the prediction to the output\n",
    "    predictions.append(prediction)\n",
    "\n",
    "  # predictions.shape => (time, batch, features)\n",
    "  predictions = tf.stack(predictions)\n",
    "  # predictions.shape => (batch, time, features)\n",
    "  predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "  return predictions\n",
    "\n",
    "FeedBack.call = call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(feedback_model, multi_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
    "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(feedback_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(multi_performance))\n",
    "width = 0.3\n",
    "\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
    "\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
    "           rotation=45)\n",
    "plt.ylabel(f'MAE (average over all times and outputs)')\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in multi_performance.items():\n",
    "  print(f'{name:8s}: {value[1]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling:\n",
    "# Using sklearn package to model data :\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "numpy.random.seed(7)\n",
    "classifiers = [\n",
    "    #svm.SVR(),\n",
    "    #linear_model.SGDRegressor(),\n",
    "    #linear_model.BayesianRidge(),\n",
    "    #linear_model.LassoLars(),\n",
    "    #linear_model.ARDRegression(), # parameters to avoid negative values \n",
    "    #linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.LinearRegression()\n",
    "]\n",
    "X = df[['cpu', 'mem', 'replica', 'requests', 'totalcpu', 'totalmemory','totalcpuUtilization', 'totalmemoryUtilization']]\n",
    "print(X.tail())\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "print(X_normalized)\n",
    "train_x, test_x, train_y, test_y = np.asarray(train_test_split(X, df['responsetime'], test_size=0.1))\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    regr = item\n",
    "    #train_x = preprocessing.normalize(train_x, norm='l2')\n",
    "    regr.fit(train_x,train_y)\n",
    "    #test_x = preprocessing.normalize(test_x, norm='l2')\n",
    "    #Now lets do prediction of data:\n",
    "    Y_pred = regr.predict(test_x)\n",
    "    #print(Y_pred)\n",
    "    # Check accuracy:\n",
    "    from sklearn.metrics import r2_score\n",
    "    R = r2_score(test_y , Y_pred)\n",
    "    print ('R :',R)\n",
    "    plt.scatter(range(0,len(test_y)),test_y)\n",
    "    plt.scatter(range(0,len(Y_pred)),Y_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack three slices, the length of the total window:\n",
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "\n",
    "\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_x = np.array(test[X])\n",
    "#test_y = np.array(test[Y])\n",
    "# The coefficients:\n",
    "#print(\"coefficients : \",regr.coef_) #Slope\n",
    "#print(\"Intercept : \",regr.intercept_) #Intercept\n",
    "#coeff_data = pd.DataFrame(regr.coef_ , X , columns=['Coefficients'])\n",
    "#coeff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets do prediction of data:\n",
    "#Y_pred = regr.predict(test_x)\n",
    "# Check accuracy:\n",
    "#from sklearn.metrics import r2_score\n",
    "#R = r2_score(test_y , Y_pred)\n",
    "#print ('R :',R)\n",
    "#plt.scatter(range(0,len(test_y)),test_y)\n",
    "#plt.scatter(range(0,len(Y_pred)),Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "cwd = os.getcwd()\n",
    "output_dir = os.path.join(cwd, \"../data\")\n",
    "df = pd.read_csv(os.path.join(output_dir, \"combined_csv.csv\"))\n",
    "df = df.drop(df[df.responsetime > 3].index)\n",
    "X = df[['cpu', 'mem', 'replica', 'requests', 'totalcpu', 'totalmemory', 'totalcpuUtilization', 'totalmemoryUtilization']]\n",
    "y = df[['responsetime']]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "train_x, test_x, train_y, test_y = np.asarray(train_test_split(X_normalized, y, test_size=0.33))\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=train_x.shape[1], activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y,validation_data=(test_x,test_y), epochs=150, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(train_x, train_y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to normalize\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = df[['cpu', 'mem', 'replica','requests','totalcpu']]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "y = df[['responsetime']]\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_normalized, y, epochs=150, batch_size=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
